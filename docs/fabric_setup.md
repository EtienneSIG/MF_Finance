# Guide de D√©ploiement - Microsoft Fabric (Sc√©nario Finance)

## üéØ Objectif

Ce guide d√©crit **√©tape par √©tape** comment d√©ployer la d√©mo Finance Performance Management dans Microsoft Fabric.

**Pr√©requis** :
- Un compte Microsoft Fabric (trial ou licence)
- Les donn√©es g√©n√©r√©es localement (voir README.md)
- Un workspace Fabric cr√©√©

**Dur√©e estim√©e** : 30-40 minutes

---

## üìã Vue d'Ensemble du D√©ploiement

```
√âtape 1: Cr√©er un Lakehouse
√âtape 2: Uploader les donn√©es vers OneLake
√âtape 3: Cr√©er des OneLake Shortcuts (optionnel)
√âtape 4: Charger les CSV en tables Delta
√âtape 5: Cr√©er un Semantic Model
√âtape 6: Configurer le Fabric Data Agent
√âtape 7: Tester et valider
```

---

## √âtape 1 : Cr√©er un Lakehouse

### 1.1 Acc√©der au Workspace

1. Ouvrir [Microsoft Fabric](https://app.fabric.microsoft.com/)
2. S√©lectionner ou cr√©er un workspace (ex: `Demo-Finance`)
3. V√©rifier que vous √™tes dans l'exp√©rience **Data Engineering**

### 1.2 Cr√©er le Lakehouse

1. Cliquer sur **+ New** ‚Üí **Lakehouse**
2. Nom : `Finance_Lakehouse`
3. Cliquer sur **Create**

‚úÖ **R√©sultat attendu** : Un Lakehouse vide avec deux sections : **Tables** et **Files**.

---

## √âtape 2 : Uploader les Donn√©es vers OneLake

### 2.1 Pr√©parer les Donn√©es Locales

Sur votre machine locale, les donn√©es g√©n√©r√©es sont dans :
```
data/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ finance/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chart_of_accounts.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ general_ledger.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cost_centers.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ budgets.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forecasts.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ allocations.csv
‚îÇ   ‚îî‚îÄ‚îÄ business/
‚îÇ       ‚îú‚îÄ‚îÄ customers.csv
‚îÇ       ‚îú‚îÄ‚îÄ products.csv
‚îÇ       ‚îú‚îÄ‚îÄ invoices.csv
‚îÇ       ‚îú‚îÄ‚îÄ invoice_lines.csv
‚îÇ       ‚îî‚îÄ‚îÄ payments.csv
```

### 2.2 Upload via l'Interface Fabric

**Option A : Upload direct**

1. Dans le Lakehouse, aller dans **Files**
2. Cr√©er une structure de dossiers :
   - Cliquer sur **Upload** ‚Üí **Upload folder**
   - S√©lectionner `data/raw/finance`
   - R√©p√©ter pour `data/raw/business`

**Option B : Upload via OneLake File Explorer (recommand√©)**

1. Installer [OneLake File Explorer](https://www.microsoft.com/en-us/download/details.aspx?id=105222)
2. Ouvrir OneLake File Explorer
3. Naviguer vers votre workspace ‚Üí `Finance_Lakehouse` ‚Üí **Files**
4. Copier-coller les dossiers `finance/` et `business/` depuis votre explorateur Windows

‚úÖ **R√©sultat attendu** : Structure de dossiers visible dans **Files** du Lakehouse.

---

## √âtape 3 : Cr√©er des OneLake Shortcuts (optionnel)

### 3.1 Principe des Shortcuts

Les **OneLake Shortcuts** cr√©ent des liens symboliques sans duplication de donn√©es.

**Pour cette d√©mo** : Optionnel si les fichiers sont d√©j√† dans le Lakehouse.

### 3.2 Cr√©er un Shortcut (Exemple : CSV Finance)

1. Dans le Lakehouse, section **Files**
2. Clic droit sur la racine ‚Üí **New shortcut**
3. Choisir **OneLake**
4. S√©lectionner :
   - **Workspace** : Demo-Finance
   - **Item** : Finance_Lakehouse
   - **Path** : `Files/raw/finance`
5. Nommer le shortcut : `finance_data`
6. Cliquer sur **Create**

‚úÖ **R√©sultat attendu** : Ic√¥ne de shortcut visible dans Files.

---

## √âtape 4 : Charger les CSV en Tables Delta

### 4.1 Cr√©er des Tables depuis les CSV

**M√©thode A : Via l'interface**

1. Dans **Files**, naviguer vers `raw/finance/chart_of_accounts.csv`
2. Clic droit ‚Üí **Load to new table**
3. Configurer :
   - **Table name** : `chart_of_accounts`
   - **Delimiter** : Comma
   - **First row has headers** : ‚úÖ Yes
   - **Infer schema** : ‚úÖ Yes
4. Cliquer sur **Load**

R√©p√©ter pour toutes les tables :

**Tables Finance (6)** :
- `chart_of_accounts`
- `general_ledger`
- `cost_centers`
- `budgets`
- `forecasts`
- `allocations`

**Tables Business (5)** :
- `customers`
- `products`
- `invoices`
- `invoice_lines`
- `payments`

**M√©thode B : Via Notebook (pour automatisation)**

```python
# Notebook: Load CSV to Delta Tables

from pyspark.sql import SparkSession

# Chemins des fichiers Finance
finance_files = {
    "chart_of_accounts": "Files/raw/finance/chart_of_accounts.csv",
    "general_ledger": "Files/raw/finance/general_ledger.csv",
    "cost_centers": "Files/raw/finance/cost_centers.csv",
    "budgets": "Files/raw/finance/budgets.csv",
    "forecasts": "Files/raw/finance/forecasts.csv",
    "allocations": "Files/raw/finance/allocations.csv"
}

# Chemins des fichiers Business
business_files = {
    "customers": "Files/raw/business/customers.csv",
    "products": "Files/raw/business/products.csv",
    "invoices": "Files/raw/business/invoices.csv",
    "invoice_lines": "Files/raw/business/invoice_lines.csv",
    "payments": "Files/raw/business/payments.csv"
}

# Fusionner
all_files = {**finance_files, **business_files}

# Charger chaque CSV en table Delta
for table_name, file_path in all_files.items():
    df = spark.read.csv(file_path, header=True, inferSchema=True)
    df.write.format("delta").mode("overwrite").saveAsTable(table_name)
    print(f"‚úÖ Table {table_name} cr√©√©e avec {df.count()} lignes")
```

‚úÖ **R√©sultat attendu** : 11 tables Delta au total dans **Tables**.

### 4.2 V√©rifier les Types de Donn√©es

```sql
-- V√©rifier les dates
DESCRIBE general_ledger;
-- Attendu: entry_date DATE

DESCRIBE invoices;
-- Attendu: invoice_date DATE, due_date DATE

-- V√©rifier les montants
DESCRIBE budgets;
-- Attendu: budget_amount_eur DECIMAL
```

Si les types sont incorrects :

```python
from pyspark.sql.functions import to_date, col

# Corriger les dates du general_ledger
df = spark.table("general_ledger")
df = df.withColumn("entry_date", to_date(col("entry_date"), "yyyy-MM-dd"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("general_ledger")
```

---

## √âtape 5 : Cr√©er un Semantic Model

### 5.1 Cr√©er le Semantic Model

1. Dans le Lakehouse, cliquer sur **New semantic model**
2. Nom : `Finance_Model`
3. S√©lectionner les tables √† inclure :
   - ‚úÖ **Finance** : chart_of_accounts, general_ledger, cost_centers, budgets, forecasts, allocations
   - ‚úÖ **Business** : customers, products, invoices, invoice_lines, payments
4. Cliquer sur **Confirm**

### 5.2 D√©finir les Relations

Cr√©er les relations suivantes :

**Relations Finance**

| Table From | Colonne From | Table To | Colonne To | Cardinalit√© |
|------------|--------------|----------|------------|-------------|
| `general_ledger` | `account_id` | `chart_of_accounts` | `account_id` | Many-to-One |
| `general_ledger` | `cost_center_id` | `cost_centers` | `cost_center_id` | Many-to-One |
| `budgets` | `account_id` | `chart_of_accounts` | `account_id` | Many-to-One |
| `budgets` | `cost_center_id` | `cost_centers` | `cost_center_id` | Many-to-One |
| `forecasts` | `account_id` | `chart_of_accounts` | `account_id` | Many-to-One |
| `forecasts` | `cost_center_id` | `cost_centers` | `cost_center_id` | Many-to-One |
| `allocations` | `to_cost_center_id` | `cost_centers` | `cost_center_id` | Many-to-One |

**Relations Business**

| Table From | Colonne From | Table To | Colonne To | Cardinalit√© |
|------------|--------------|----------|------------|-------------|
| `invoices` | `customer_id` | `customers` | `customer_id` | Many-to-One |
| `invoice_lines` | `invoice_id` | `invoices` | `invoice_id` | Many-to-One |
| `invoice_lines` | `product_id` | `products` | `product_id` | Many-to-One |
| `payments` | `invoice_id` | `invoices` | `invoice_id` | Many-to-One |

### 5.3 Cr√©er des Mesures DAX

```dax
// ============================================
// Mesures Revenue
// ============================================

Total Revenue = 
SUMX(
    invoice_lines,
    invoice_lines[quantity] * invoice_lines[unit_price_eur] * (1 - invoice_lines[discount_pct])
)

Revenue from GL = 
CALCULATE(
    SUM(general_ledger[credit_amount_eur]),
    chart_of_accounts[account_type] = "Revenue"
)

// ============================================
// Mesures COGS & Gross Margin
// ============================================

Total COGS = SUM(invoice_lines[cogs_eur])

COGS from GL = 
CALCULATE(
    SUM(general_ledger[debit_amount_eur]),
    chart_of_accounts[account_name] = "Achats mati√®res"
)

Gross Margin EUR = [Total Revenue] - [Total COGS]

Gross Margin % = 
DIVIDE(
    [Gross Margin EUR],
    [Total Revenue],
    0
) * 100

// ============================================
// Mesures Operating Expenses
// ============================================

Total Opex = 
CALCULATE(
    SUM(general_ledger[debit_amount_eur]),
    chart_of_accounts[account_type] = "Expense",
    chart_of_accounts[account_name] <> "Achats mati√®res"
)

// ============================================
// Mesures Profitability
// ============================================

EBITDA = [Gross Margin EUR] - [Total Opex]

EBITDA % = 
DIVIDE(
    [EBITDA],
    [Total Revenue],
    0
) * 100

Net Profit = [EBITDA]  // Simplifi√© (sans int√©r√™ts, taxes, etc.)

Net Profit % = 
DIVIDE(
    [Net Profit],
    [Total Revenue],
    0
) * 100

// ============================================
// Mesures Budget
// ============================================

Total Budget = SUM(budgets[budget_amount_eur])

Actual Expenses = 
CALCULATE(
    SUM(general_ledger[debit_amount_eur]),
    chart_of_accounts[account_type] = "Expense"
)

Budget Variance EUR = [Actual Expenses] - [Total Budget]

Budget Variance % = 
DIVIDE(
    [Budget Variance EUR],
    [Total Budget],
    0
) * 100

// ============================================
// Mesures Forecast
// ============================================

Total Forecast = SUM(forecasts[forecast_amount_eur])

Forecast Accuracy % = 
DIVIDE(
    [Actual Expenses],
    [Total Forecast],
    0
) * 100

// ============================================
// Mesures Cash & DSO
// ============================================

Accounts Receivable = 
CALCULATE(
    SUM(invoices[total_amount_eur]),
    invoices[status] <> "Paid"
)

DSO = 
DIVIDE(
    [Accounts Receivable],
    [Total Revenue] / 365,
    0
)

Overdue Amount = 
CALCULATE(
    SUM(invoices[total_amount_eur]),
    invoices[due_date] < TODAY(),
    invoices[status] <> "Paid"
)

Avg Days Overdue = AVERAGE(payments[days_overdue])

// ============================================
// Mesures Counts
// ============================================

Total Invoices = COUNTROWS(invoices)

Total Customers = COUNTROWS(customers)

Total Products = COUNTROWS(products)
```

### 5.4 Publier le Semantic Model

1. Cliquer sur **File** ‚Üí **Save**
2. Le mod√®le est automatiquement publi√© dans le workspace

‚úÖ **R√©sultat attendu** : Semantic Model disponible, pr√™t pour Power BI et Data Agent.

---

## √âtape 6 : Configurer le Fabric Data Agent

### 6.1 Activer la Preview Data Agent

1. Aller dans **Settings** (‚öôÔ∏è) ‚Üí **Tenant settings**
2. Rechercher **Fabric Data Agent**
3. Activer la preview pour le workspace

### 6.2 Cr√©er le Data Agent

1. Dans le workspace, cliquer sur **+ New** ‚Üí **Data Agent**
2. Nom : `Finance_Controller`
3. S√©lectionner la source :
   - **Type** : Semantic Model
   - **Source** : `Finance_Model`
4. Cliquer sur **Create**

### 6.3 Configurer les Instructions (System Prompt)

1. Ouvrir le Data Agent
2. Aller dans **Settings** ‚Üí **Instructions**
3. Coller le contenu de [`data_agent_instructions.md`](data_agent_instructions.md)
4. Sauvegarder

### 6.4 Tester le Data Agent

Poser une premi√®re question :
```
Quel est le chiffre d'affaires total ?
```

R√©ponse attendue : `~31M‚Ç¨`

Si la r√©ponse est correcte ‚úÖ, passer √† l'√©tape 7.

---

## √âtape 7 : Tester et Valider

### 7.1 Questions de Validation

Poser les questions de [`questions_demo.md`](questions_demo.md) :

1. ‚úÖ Quel est le chiffre d'affaires total de l'ann√©e ?
2. ‚úÖ Quelle est la marge brute globale ?
3. ‚úÖ Quels centres de co√ªts ont d√©pass√© leur budget ?
4. ‚úÖ Quel est le DSO actuel ?
5. ‚úÖ Pourquoi la marge brute baisse en Q2 ?

**Crit√®re de succ√®s** : Au moins 16/20 questions fonctionnent correctement.

### 7.2 Cr√©er un Dashboard Power BI

1. Dans le workspace, cliquer sur **+ New** ‚Üí **Report**
2. S√©lectionner `Finance_Model` comme source
3. Cr√©er quelques visuels :

**Page 1 : P&L**
   - Card : Total Revenue, Gross Margin %, EBITDA, Net Profit
   - Waterfall Chart : P&L Breakdown
   - Line Chart : Revenue & EBITDA by Month

**Page 2 : Budget Analysis**
   - Card : Total Budget, Actual, Variance %
   - Bar Chart : Budget Variance by Cost Center
   - Table : Top 10 Overrun Accounts

**Page 3 : Cash & DSO**
   - Card : DSO, Overdue Amount
   - Line Chart : DSO Trend
   - Table : Top Overdue Customers

4. Sauvegarder le rapport : `Finance_Dashboard`

### 7.3 V√©rifier les Permissions

Si la d√©mo doit √™tre partag√©e :
1. Aller dans **Workspace settings** ‚Üí **Access**
2. Ajouter les viewers/contributors
3. V√©rifier que le Semantic Model est partag√©

---

## üéâ D√©ploiement Termin√©

Vous avez maintenant :
- ‚úÖ Un Lakehouse avec 11 tables Delta
- ‚úÖ Des OneLake Shortcuts (optionnel)
- ‚úÖ Un Semantic Model complet avec relations et mesures
- ‚úÖ Un Data Agent fonctionnel
- ‚úÖ Un dashboard Power BI Finance

**Prochaines √©tapes** :
- Tester les 20 questions de la d√©mo
- Personnaliser le dashboard
- Pr√©parer le pitch ([demo_story.md](demo_story.md))

---

## üîß Troubleshooting

### Probl√®me : Le Data Agent ne r√©pond pas correctement

**Solutions** :
1. V√©rifier que le Semantic Model est publi√©
2. V√©rifier les relations entre tables (11 relations au total)
3. V√©rifier que toutes les mesures DAX sont bien calcul√©es
4. Simplifier la question (utiliser termes exacts)

### Probl√®me : Erreurs de type de donn√©es

**Solutions** :
```python
from pyspark.sql.functions import to_date, col

# Corriger les dates
df = spark.table("general_ledger")
df = df.withColumn("entry_date", to_date(col("entry_date"), "yyyy-MM-dd"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("general_ledger")
```

### Probl√®me : Les montants ne matchent pas

**Solutions** :
- V√©rifier que les mesures DAX utilisent les bonnes tables
- Revenue : utiliser `invoice_lines` (source de v√©rit√©)
- Budget : utiliser `budgets`
- Actual : utiliser `general_ledger`

---

## ‚úÖ Checklist de D√©ploiement

- [ ] Lakehouse cr√©√©
- [ ] Donn√©es upload√©es (11 CSV)
- [ ] OneLake Shortcuts cr√©√©s (optionnel)
- [ ] 11 tables Delta cr√©√©es et v√©rifi√©es
- [ ] Semantic Model cr√©√©
- [ ] Relations Finance d√©finies (7 relations)
- [ ] Relations Business d√©finies (4 relations)
- [ ] Mesures DAX ajout√©es (Revenue, Margin, Budget, DSO...)
- [ ] Data Agent configur√©
- [ ] Instructions du Data Agent ajout√©es
- [ ] Questions de test valid√©es (‚â•16/20)
- [ ] Dashboard Power BI cr√©√©
- [ ] Permissions partag√©es (si n√©cessaire)

**Si toutes les cases sont coch√©es, la d√©mo est pr√™te ! üöÄ**
